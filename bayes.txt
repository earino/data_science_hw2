> library("e1071")
> classifier <- naiveBayes(train.data, train.labels)
> table(predict(classifier, test.labels), test.data)
Error in table(predict(classifier, test.labels), test.data) : 
  all arguments must have the same length
> predictions <- predict(classifier, test.data)
> table(predictions, test.labels)
           test.labels
predictions  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 26
         1   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         2   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         3   3 12  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         4   0  7  7 12  2  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         5   0  2 18 25 19  5  5  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         6   0  0  0 23 48 21 12 11  2  1  0  1  1  1  0  0  0  0  0  0  0  0  0
         7   0  0  1  6 32 31 23 14  8  4  5  2  0  3  1  1  0  0  0  0  0  0  0
         8   0  0  0  6 20 42 26 21 14 18  7 12  8  1  1  2  0  2  1  1  0  0  0
         9   0  0  0  1  7 42 69 60 32 12 19 10  7  6  4  2  2  0  1  1  0  0  0
         10  0  0  0  0  0  9 38 42 37 13  6  8  8  4  5  0  1  3  1  0  1  0  1
         11  0  0  0  1  0  4 20 45 59 20 14  5  9  3  4  2  4  0  1  0  0  0  0
         12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         14  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         16  0  0  0  0  0  0  0  0  0  0  2  0  1  0  0  0  0  0  0  2  1  0  0
         17  0  0  0  0  0  0  0  0  2  0  1  0  0  0  0  1  0  0  1  0  0  0  0
         18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         20  0  0  0  0  0  0  0  2  2  1  2  2  2  2  3  1  0  0  0  0  0  0  0
         21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  1  0
         22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         24  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
         27  0  0  0  0  0  0  1  4  3  5  1  3  0  2  1  0  0  1  0  0  0  0  0
         29  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0
> classifier

Naive Bayes Classifier for Discrete Predictors

Call:
naiveBayes.default(x = train.data, y = train.labels)

A-priori probabilities:
train.labels
           1            2            3            4            5            6            7 
0.0003421143 0.0003421143 0.0041053712 0.0123161136 0.0290797126 0.0632911392 0.0899760520 
           8            9           10           11           12           13           14 
0.1412931919 0.1693465618 0.1481354772 0.1115292508 0.0660280534 0.0499486829 0.0283954841 
          15           16           17           18           19           20           21 
0.0229216558 0.0153951420 0.0133424564 0.0112897708 0.0085528567 0.0065001711 0.0030790284 
          22           23           24           25           27           29 
0.0006842285 0.0023947999 0.0003421143 0.0003421143 0.0006842285 0.0003421143 

Conditional probabilities:
            length
train.labels      [,1]       [,2]
          1  0.0750000         NA
          2  0.1500000         NA
          3  0.1804167 0.03621014
          4  0.2265278 0.05320875
          5  0.2896471 0.06295685
          6  0.3740811 0.07041584
          7  0.4225095 0.07877143
          8  0.4969613 0.07963145
          9  0.5476465 0.08239498
          10 0.5765012 0.08598051
          11 0.5976074 0.08975494
          12 0.5900259 0.09125784
          13 0.5804110 0.08893335
          14 0.5856024 0.07849731
          15 0.5735075 0.06691251
          16 0.5988889 0.06752011
          17 0.5973077 0.06919505
          18 0.5989394 0.06864489
          19 0.5876000 0.06923872
          20 0.6097368 0.05051055
          21 0.6266667 0.07709572
          22 0.6200000 0.04949747
          23 0.5792857 0.11734666
          24 0.7000000         NA
          25 0.6450000         NA
          27 0.6075000 0.08131728
          29 0.7000000         NA

            diameter
train.labels      [,1]       [,2]
          1  0.0550000         NA
          2  0.1000000         NA
          3  0.1320833 0.02526751
          4  0.1650000 0.04229151
          5  0.2135882 0.05027669
          6  0.2813243 0.05808308
          7  0.3228137 0.06367612
          8  0.3848184 0.06545048
          9  0.4258586 0.06700973
          10 0.4509353 0.07047945
          11 0.4687730 0.07308181
          12 0.4620466 0.07344097
          13 0.4569521 0.07321761
          14 0.4631928 0.06248697
          15 0.4550746 0.05697217
          16 0.4784444 0.05930298
          17 0.4738462 0.05916593
          18 0.4768182 0.05640005
          19 0.4644000 0.06455489
          20 0.4868421 0.04586243
          21 0.5000000 0.06576473
          22 0.4950000 0.06363961
          23 0.4592857 0.09198861
          24 0.5400000         NA
          25 0.4900000         NA
          27 0.5000000 0.04949747
          29 0.5850000         NA

            height
train.labels       [,1]       [,2]
          1  0.01000000         NA
          2  0.02500000         NA
          3  0.04125000 0.01189442
          4  0.05375000 0.01818064
          5  0.07117647 0.01836545
          6  0.09124324 0.02092482
          7  0.10646388 0.02360711
          8  0.12930993 0.05554077
          9  0.14316162 0.02668329
          10 0.15450346 0.03252735
          11 0.15970859 0.02962833
          12 0.16124352 0.02874561
          13 0.15948630 0.02852542
          14 0.16421687 0.02982144
          15 0.15985075 0.02756494
          16 0.17188889 0.02892563
          17 0.17628205 0.03157526
          18 0.17484848 0.02529466
          19 0.17080000 0.02465090
          20 0.17157895 0.01936869
          21 0.17777778 0.02538591
          22 0.19250000 0.03181981
          23 0.17214286 0.02998015
          24 0.21500000         NA
          25 0.21500000         NA
          27 0.20250000 0.03181981
          29 0.18500000         NA

            whole_weight
train.labels       [,1]       [,2]
          1  0.00200000         NA
          2  0.01500000         NA
          3  0.03075000 0.01686915
          4  0.06333333 0.04215617
          5  0.13281176 0.08259288
          6  0.27462973 0.16368857
          7  0.40245247 0.23675553
          8  0.64117676 0.29999040
          9  0.85055354 0.36008558
          10 1.01803349 0.41871398
          11 1.13013804 0.47287757
          12 1.10432902 0.50224824
          13 1.07796918 0.46405585
          14 1.11020482 0.43576303
          15 1.02917910 0.36461116
          16 1.18120000 0.39858105
          17 1.23505128 0.49708782
          18 1.22242424 0.40531209
          19 1.13168000 0.40918957
          20 1.25605263 0.31573811
          21 1.29355556 0.36221260
          22 1.35625000 0.68978267
          23 1.17214286 0.63352215
          24 1.97800000         NA
          25 1.40600000         NA
          27 1.69800000 0.68660068
          29 1.80750000         NA

            shucked_weight
train.labels       [,1]        [,2]
          1  0.00100000          NA
          2  0.00450000          NA
          3  0.01300000 0.008295672
          4  0.02620833 0.017957639
          5  0.06297059 0.057019439
          6  0.12532432 0.077971655
          7  0.18461787 0.117785083
          8  0.29396368 0.147661290
          9  0.38616869 0.180533488
          10 0.45320323 0.204696400
          11 0.49788497 0.234196065
          12 0.47395078 0.247909912
          13 0.43607877 0.218999824
          14 0.43401807 0.184448989
          15 0.39902985 0.146862693
          16 0.44076667 0.154706305
          17 0.46716667 0.203429004
          18 0.45768182 0.151482199
          19 0.42562000 0.191583765
          20 0.46734211 0.134709157
          21 0.47305556 0.126928485
          22 0.53750000 0.289913780
          23 0.39842857 0.246683067
          24 0.66750000          NA
          25 0.42650000          NA
          27 0.53900000 0.303348809
          29 0.70550000          NA

            viscera_weight
train.labels       [,1]        [,2]
          1  0.00050000          NA
          2  0.00400000          NA
          3  0.00675000 0.003633806
          4  0.01331944 0.009247511
          5  0.02890588 0.018118738
          6  0.05837838 0.034683861
          7  0.08783650 0.053669062
          8  0.13801695 0.068446526
          9  0.18697778 0.083911454
          10 0.22548268 0.096611402
          11 0.25000307 0.110549001
          12 0.24066839 0.116497637
          13 0.23628425 0.107665060
          14 0.24357229 0.096699280
          15 0.22314925 0.081199764
          16 0.24892222 0.081278069
          17 0.25276923 0.094852368
          18 0.25292424 0.091411426
          19 0.24618000 0.113265073
          20 0.25197368 0.076009406
          21 0.27311111 0.087965113
          22 0.24525000 0.115611959
          23 0.26014286 0.156343296
          24 0.31250000          NA
          25 0.22850000          NA
          27 0.29800000 0.131521861
          29 0.32150000          NA

            shell_weight
train.labels        [,1]        [,2]
          1  0.001500000          NA
          2  0.005000000          NA
          3  0.008833333 0.004443245
          4  0.019402778 0.013812427
          5  0.038452941 0.021987906
          6  0.080086486 0.049839259
          7  0.113026616 0.059867740
          8  0.179062954 0.076366537
          9  0.236815152 0.092146390
          10 0.285236721 0.106552223
          11 0.314935583 0.117843901
          12 0.322748705 0.134227207
          13 0.321650685 0.120482069
          14 0.340246988 0.135996287
          15 0.319268657 0.118739890
          16 0.393100000 0.140567381
          17 0.397025641 0.178506706
          18 0.389409091 0.168910454
          19 0.356800000 0.114408624
          20 0.432263158 0.129670883
          21 0.445555556 0.152221969
          22 0.427500000 0.222738636
          23 0.362857143 0.138920155
          24 0.710000000          NA
          25 0.510000000          NA
          27 0.705000000 0.254558441
          29 0.475000000          NA

